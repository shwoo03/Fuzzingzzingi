# WHS2기 웹 퍼저 프로젝트

## 프로젝트 목표
- WHS2기 프로젝트임을 명확히 알립니다.
- CTF 등에서 자동화된 초기 정찰과 빠른 취약점 탐색을 수행하는 웹 퍼저를 구현합니다.
- 탐지 최소화를 지향하면서도 고수준 크롤링으로 커버리지를 극대화합니다.
- 각 취약점 탐지 로직을 고도화해 사용자의 초기 접근을 더 편리하게 만듭니다.

## 현재 작업 현황
- 크롤러 리팩터링 계획을 `docs/plans.md`에 정리했습니다.
- Selenium 브라우저 세션을 헬퍼 클래스로 분리하고, URL 정규화/중복 필터링을 일원화했습니다.
- 수집 URL은 `output.txt`에 UTF-8로 저장하며, 동일 도메인·중복 링크를 자동으로 배제합니다.

## 크롤러 실행 개요
- 기본 실행 예시  
  `scrapy runspider crawler/spiders/crawler.py -a start_url=http://target -a proxy_url=http://127.0.0.1:8080`
- 쿠키 파일이 필요하면 프로젝트 루트의 `cookie_header.txt`에서 `name=value` 형식으로 불러옵니다.
- 렌더링 단계에서 간단한 `onclick` 이벤트 클릭을 시뮬레이션해 동적 링크를 더 수집합니다.

## 문서
- 리팩터링 계획 및 테스트 계획: `docs/plans.md`
