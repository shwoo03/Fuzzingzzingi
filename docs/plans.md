# 크롤러 리팩터링 계획

## 목표
- Scrapy + Selenium을 안정적으로 결합해 초기 정찰을 자동화하고, 탐지 최소화·커버리지 극대화를 동시에 추구합니다.
- URL 정규화·중복 제거·로그 수집을 일관되게 적용해 수집 품질을 높입니다.
- 설정, 브라우저 제어, 링크 추출을 모듈화해 이후 취약점 스캐너와 쉽게 연동되도록 합니다.

## 현황 점검 요약
- `crawler/spiders/crawler.py`에서 Selenium을 직접 관리하면서도 별도의 Selenium 미들웨어가 존재해 역할이 중첩되고 있습니다.
- 도메인/중복 필터링과 자바스크립트 클릭 로직이 분산돼 있어 제어 흐름이 불명확합니다.
- 설정 값(PROXY, DB 등)이 코드와 설정 파일에 중복되거나 잘못된 키(`WNLOADER_MIDDLEWARES`)로 선언돼 있습니다.
- README 및 주석의 인코딩이 깨져 가독성이 낮습니다.

## 리팩터링 방향
1) **브라우저 세션 모듈화**: Selenium 옵션, 프록시, 자바스크립트 이벤트 트리거를 한 클래스로 묶고, 스파이더는 해당 인터페이스만 사용합니다.  
2) **링크 추출·필터링 표준화**: URL 정규화 → 도메인·중복 검사 → 수집 기록 → 하위 요청 생성의 흐름을 단일 메서드 체인으로 단순화합니다.  
3) **설정 일원화 및 예외 내성 강화**: 누락된 설정 키를 정리하고, 쿠키/파일/드라이버 로딩 실패 시 명확한 로그와 안전한 종료 경로를 추가합니다.  
4) **문서 및 테스트 기반 유지보수**: 리팩터링 후 README와 계획 문서를 최신화하고, 간단한 브라우저 동작 스모크 테스트를 수행합니다.

## 작업 목록
- [x] 브라우저 세션 헬퍼(프록시·헤드리스·안티디텍션 옵션) 추가 및 스파이더에서 사용.
- [x] 링크 정규화·필터링·기록 로직을 메서드화하고 중복 체크 일원화.
- [x] 설정 키 오타 점검 및 README 인코딩/내용 최신화.
- [x] 스모크용 브라우저 테스트(예: example.com 렌더링) 후 에러 해결.

## 테스트 계획
- 로컬/헤드리스 크롬으로 단일 URL 렌더링 스모크 테스트 실행.
- 로그에서 수집 URL 중복 없이 기록되는지 확인.
